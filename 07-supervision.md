---
layout: page
title: Supervision
permalink: /supervision/
---

## PhD Theses

- **S. Cuervo** – *Deep learning for speech perception* (2022–present)  
  100% supervision  
  AI for speech and language perception

- **S. Baroudi** – *Joint speech diarization and separation* (2023–present)  
  40% supervision  
  AI for joint speech separation and diarization

- **A. Balleroy** – *Large-scale exploratory modeling of early language acquisition* (2023–present)  
  33% supervision  
  AI for speech and cognition

- **J. Cauzinille** – *Self-supervised representation learning of primate vocalizations, from analysis to synthesis* (2022–present)  
  33% supervision  
  AI for bioacoustics and speech

- **C. Boittiaux** – *Visual localisation for long-term monitoring of the deep sea* (2020–2023)  
  25% supervision  
  Underwater computer vision

- **P. Best** – *Intelligent bioacoustics for real-time prediction, detection and underwater surveillance of wildlife and manage the risk of collision with maritime traffic* (2019–2022)  
  33% supervision  
  AI for underwater multichannel bioacoustic data

- **G. Sanchez** – *Study and development of video characterisation algorithms. Application to the automatic indexing of audiovisual content.* (2018–2022)  
  33% supervision  
  Audio-visual scene analysis and self-supervised learning

- **M. Ferrari** – *Study of bio-inspired sonar based on the modelling of a complete transmission-propagation-reception chain. Validation on sperm whales* (2017–2020)  
  33% supervision  
  Multichannel and multimodal underwater bioacoustics

## Research Assistants
- **C. Bernard** – *Bird vocalisation monitoring and recognition in the field* (2024–present)  
  AI for bioacoustics
- **M. Antunes** – *An analysis-by-synthesis approach to the study of musical texture* (2024–present)  
  AI for music
- **P. Best** – *Spatialised bioacoustics for the analysis of turn-taking in non-human interactions* (2022–present)  
  AI for bioacoustics


## Master Theses
- **B. Aydin** (2025, 33%) – *Zero-Shot and Few-Shot Classification using Marine Mammals Sound*. Bioacoustics.
- **F. Amor** (2024, 33%) – *Data Driven modelling of Sea Ice Drift*. Ocean sensing and modelling.
- **M. R. Rahman** (2024, 50%) – *Self-Supervised Scale Consistent Depth and Ego-motion Learning from Monocular Video for underwater robots*. Underwater computer vision.
- **O. Ojekanmi** (2024, 50%) – *High-Fidelity 3D Reconstruction of Underwater Scenes Using NeRFs*. Underwater computer vision.
- **M. S. Rahman** (2024, 50%) – *Enhancing Underwater Object Detection and Out-of-Distribution Detection*. Underwater computer vision.
- **L. A. Grajeda** (2023, 50%) – *AI Framework for Human-Robot Cooperative Operation through Hand Gesture Recognition*. Underwater computer vision.
- **V. L. Gomes** (2023, 50%) – *Learning-based control for surface vehicles*. Underwater robotic control.
- **A. Kaibaldiyev** (2023, 50%) – *Self-supervised multimodal representations for marine robotics*. Computer vision and remote sensing.
- **J. Philibert** (2020, 33%) – *Neural ODEs and Direct Feedback Alignment*. Multichannel bioacoustics.
- **N. Thellier** (2020, 33%) – *Joint classification and localisation for underwater data*. Multichannel bioacoustics.
- **C. Lamothe** (2019, 33%) – *Language constraints in unsupervised symbol discovery*. Unsupervised learning on speech data.

## Short Master Internships (<2 months)
- **A. Badawi** (2024) – *Deep learning for speech modeling*.
- **E. Deowan** (2024) – *DRL and multi-modal sensor fusion for underwater navigation*.
- **R. Rincón** (2023) – *Unsupervised depth estimation with deep learning*.
- **O. Ojekanmi** (2023) – *3D underwater scene understanding with machine learning*.
- **A. Grajeda** (2022) – *Alternative priors for homography-based cost functions*.
- **V. Gomes** (2022) – *Experimentation with priors for homography-based cost functions*.
- **A. A. Khan** (2022) – *Color correction methods for underwater imaging*.
