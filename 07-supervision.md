---
layout: page
title: Supervision
permalink: /supervision/
---

## Supervision

### PhD Theses
- **S. Baroudi** (2023–present) – *Joint speech diarization and separation*. AI for joint speech separation and diarization.
- **A. Balleroy** (2023–present) – *Large-scale exploratory modeling of early language acquisition*. AI for speech and cognition.
- **S. Cuervo** (2022–present) – *Deep learning for speech perception*. AI for speech and language perception.
- **J. Cauzinilles** (2022–present) – *Self-supervised representation learning of primate vocalizations, from analysis to synthesis*. AI for bioacoustics and speech.
- **C. Boittiaux** (2020–2023) – *Visual localisation for long-term monitoring of the deep sea*. Underwater computer vision.
- **P. Best** (2019–2022) – *Intelligent bioacoustics for real-time prediction, detection and underwater surveillance of wildlife and risk management with maritime traffic*. AI for underwater multichannel bioacoustic data.
- **G. Sanchez** (2018–2022) – *Video characterisation algorithms for automatic indexing of audiovisual content*. Audio-visual scene analysis and self-supervised learning.
- **M. Ferrari** (2017–2020) – *Bio-inspired sonar based on a complete transmission-propagation-reception chain*. Multichannel and multimodal underwater bioacoustics.

### Master Theses
- **B. Aydin** (2025, 33%) – *Zero-Shot and Few-Shot Classification using Marine Mammals Sound*. Bioacoustics.
- **F. Amor** (2024, 33%) – *Data Driven modelling of Sea Ice Drift*. Ocean sensing and modelling.
- **M. R. Rahman** (2024, 50%) – *Self-Supervised Scale Consistent Depth and Ego-motion Learning from Monocular Video for underwater robots*. Underwater computer vision.
- **O. Ojekanmi** (2024, 50%) – *High-Fidelity 3D Reconstruction of Underwater Scenes Using NeRFs*. Underwater computer vision.
- **M. S. Rahman** (2024, 50%) – *Enhancing Underwater Object Detection and Out-of-Distribution Detection*. Underwater computer vision.
- **L. A. Grajeda** (2023, 50%) – *AI Framework for Human-Robot Cooperative Operation through Hand Gesture Recognition*. Underwater computer vision.
- **V. L. Gomes** (2023, 50%) – *Learning-based control for surface vehicles*. Underwater robotic control.
- **A. Kaibaldiyev** (2023, 50%) – *Self-supervised multimodal representations for marine robotics*. Computer vision and remote sensing.
- **J. Philibert** (2020, 33%) – *Neural ODEs and Direct Feedback Alignment*. Multichannel bioacoustics.
- **N. Thellier** (2020, 33%) – *Joint classification and localisation for underwater data*. Multichannel bioacoustics.
- **C. Lamothe** (2019, 33%) – *Language constraints in unsupervised symbol discovery*. Unsupervised learning on speech data.

### Short Master Internships (<2 months)
- **A. Badawi** (2024) – *Deep learning for speech modeling*.
- **E. Deowan** (2024) – *DRL and multi-modal sensor fusion for underwater navigation*.
- **R. Rincón** (2023) – *Unsupervised depth estimation with deep learning*.
- **O. Ojekanmi** (2023) – *3D underwater scene understanding with machine learning*.
- **A. Grajeda** (2022) – *Alternative priors for homography-based cost functions*.
- **V. Gomes** (2022) – *Experimentation with priors for homography-based cost functions*.
- **A. A. Khan** (2022) – *Color correction methods for underwater imaging*.
